{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, embed_size, device):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    # Number of input features is embed_size.\n",
    "    self.layer_1 = nn.Linear(embed_size, 64)\n",
    "    self.layer_2 = nn.Linear(64, 64)\n",
    "    self.layer_out = nn.Linear(64, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "    self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "    self.device = device\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    # print(\"start binary classification\")\n",
    "    # print(inputs.shape)\n",
    "    # print(inputs)\n",
    "    x = self.relu(self.layer_1(inputs))\n",
    "    x = self.batchnorm1(x)\n",
    "    x = self.relu(self.layer_2(x))\n",
    "    x = self.batchnorm2(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.layer_out(x)\n",
    "    #if math.isnan (x[0][0]):\n",
    "    #  print(src)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, d_model, seq_len, nhead, dim_feedforward, nlayers, device, dropout = 0.5):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.seq_len = seq_len\n",
    "    self.nhead = nhead\n",
    "    self.dim_feedforward = dim_feedforward\n",
    "    self.nlayers = nlayers\n",
    "    self.device = device\n",
    "    \n",
    "    self.position_embedding = nn.Embedding(seq_len, d_model)\n",
    "    encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "    self.encoder = TransformerEncoder(encoder_layer, nlayers)\n",
    "    self.binary_classifier = BinaryClassification(seq_len*d_model, device)\n",
    "\n",
    "  def forward(self, src: Tensor) -> Tensor:\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        src: Tensor, shape [seq_len, batch_size]\n",
    "        src_mask: Tensor, shape [seq_len, seq_len]\n",
    "    Returns:\n",
    "        output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "    \"\"\"\n",
    "    N, seq_length, embed_size = src.shape\n",
    "    positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "    src_ = src + self.position_embedding(positions)\n",
    "    output1 = self.encoder(src_)\n",
    "    # print(output1.shape)\n",
    "    # print(output1)\n",
    "    output = self.binary_classifier(torch.reshape(output1, (N, seq_length*embed_size))) \n",
    "\n",
    "    return output, output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test\n",
    "X_test = np.load(\"X_test.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"y_test.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data\n",
    "class TestData(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "test_data = TestData(X_test, y_test)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (position_embedding): Embedding(108, 11)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=11, out_features=11, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=11, out_features=8, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=8, out_features=11, bias=True)\n",
       "        (norm1): LayerNorm((11,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((11,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (binary_classifier): BinaryClassification(\n",
       "    (layer_1): Linear(in_features=1188, out_features=64, bias=True)\n",
       "    (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './PonziShield_tr_v1.pth'\n",
    "loaded_model = torch.load(PATH)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 108, 11])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([1, 108, 11])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1])\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "for X_batch, y_batch in test_loader:\n",
    "        #print(\"w.requires_grad:\",X_batch.requires_grad)\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        print(X_batch.shape)\n",
    "        print(y_batch.shape)\n",
    "        results,result_before_bin_classifier = loaded_model(X_batch.float())\n",
    "        print(results.shape)\n",
    "        y_batch_pred = torch.round(sigmoid(results))\n",
    "        y_pred.extend(y_batch_pred.cpu().detach().numpy())\n",
    "        y_true.extend(y_batch.cpu().detach().numpy())\n",
    "\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "for i in range(len(y_pred)):\n",
    "  if y_true[i]==y_pred[i]:\n",
    "    count_true+=1\n",
    "acc = count_true/len(y_pred)\n",
    "print(len(y_test))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tensor_inputs(embedding_dir,contract_address):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for i in range(len(contract_address)):\n",
    "        \n",
    "        # print(filtered_df.loc[i, \"address\"], filtered_df.loc[i, \"label\"])\n",
    "        fileNameToRead = embedding_dir + str(contract_address[i]) + '.csv'\n",
    "        data = pd.read_csv(fileNameToRead)\n",
    "        # Extract the relevant data (assuming the label column is named 'label')\n",
    "        features = data.iloc[:, :11].to_numpy()\n",
    "        label = data['label'][1]\n",
    "        # print(features[1], labels[1])\n",
    "        all_data.append((features))\n",
    "        all_labels.append(label)\n",
    "        # print(\"-----------------------------------------------------------------------\")\n",
    "    data_array = np.array(all_data)\n",
    "    labels_array = np.array(all_labels)\n",
    "\n",
    "    # Reshape the array to (301*108, 11) for normalization\n",
    "    reshaped_data = data_array.reshape((-1, 11))\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # Fit the scaler on the reshaped data and transform it\n",
    "    normalized_data = scaler.fit_transform(reshaped_data)\n",
    "    # Reshape the normalized data back to the original shape\n",
    "    normalized_data_array = normalized_data.reshape(data_array.shape)\n",
    "\n",
    "    data_tensor = torch.tensor(normalized_data_array, dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(labels_array, dtype=torch.float32)\n",
    "\n",
    "    print(data_tensor.shape)\n",
    "    print(labels_tensor.shape)\n",
    "    return data_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 108, 11])\n",
      "torch.Size([7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.2207, -0.2227, -0.1379,  ..., -0.6683,  3.1237, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683,  1.1492, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683,  1.1492, -0.7103],\n",
       "          ...,\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]],\n",
       " \n",
       "         [[ 3.1714,  3.1648,  1.7379,  ...,  1.3607,  3.1237,  1.4198],\n",
       "          [ 5.2067,  5.1973,  0.0358,  ...,  1.6143,  1.1492,  1.4198],\n",
       "          [ 2.8806,  2.8745,  0.1921,  ...,  1.1071,  1.1492,  1.4198],\n",
       "          ...,\n",
       "          [-0.2207, -0.2227, -0.1379,  ...,  1.1071, -0.8253,  1.4198],\n",
       "          [-0.2207, -0.2227, -0.1379,  ...,  1.6143, -0.8253,  1.4198],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.1610, -0.8253,  1.2068]],\n",
       " \n",
       "         [[-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n",
       "          [-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n",
       "          [-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n",
       "          ...,\n",
       "          [-0.2207, -0.2227, -0.1379,  ...,  1.8679,  1.1492,  1.4198],\n",
       "          [-0.2207, -0.2227, -0.1377,  ...,  1.8679,  1.1492,  1.4198],\n",
       "          [ 0.3220,  1.4033, -0.1377,  ...,  1.8679,  1.1492,  1.4198]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.5884,  1.5840, 17.3180,  ...,  0.0926,  3.1237,  1.4198],\n",
       "          [ 3.3975,  3.3906, -0.0337,  ...,  0.0926,  1.1492,  1.4198],\n",
       "          [-0.2207, -0.2227, -0.1206,  ..., -0.1610,  1.1492,  1.4198],\n",
       "          ...,\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]],\n",
       " \n",
       "         [[-0.2207, -0.2227, -0.1377,  ..., -0.4146,  3.1237, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.4146,  1.1492, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.4146,  1.1492, -0.7103],\n",
       "          ...,\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]],\n",
       " \n",
       "         [[-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          ...,\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103],\n",
       "          [-0.2207, -0.2227, -0.1379,  ..., -0.6683, -0.8253, -0.7103]]]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract_addresses = [\n",
    "    \"0x6e38a457c722c6011b2dfa06d49240e797844d66\",\n",
    "    \"0x109c4f2ccc82c4d77bde15f306707320294aea3f\",\n",
    "    \"0x793ae8c1b1a160bfc07bfb0d04f85eab1a71f4f2\",\n",
    "    \"0x5fe5b7546d1628f7348b023a0393de1fc825a4fd\",\n",
    "    \"0xd79b4c6791784184e2755b2fc1659eaab0f80456\",\n",
    "    \"0x273930d21e01ee25e4c219b63259d214872220a2\",\n",
    "    \"0xd07ce4329b27eb8896c51458468d98a0e4c0394c\"\n",
    "]\n",
    "\n",
    "create_tensor_inputs('./data/data_set/',contract_addresses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionModality(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        inductor=True,\n",
    "        embedding_dir='./data/data_set/',\n",
    "        model_path='./PonziShield_tr_v1.pth',\n",
    "        ):\n",
    "        super(TransactionModality, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.embedding_dir=embedding_dir\n",
    "        self.model = torch.load(model_path)\n",
    "\n",
    "    def forward(self, dapp_addresses, train):\n",
    "\n",
    "        if train==False:\n",
    "            # do realtime prediction\n",
    "            return\n",
    "            \n",
    "        \n",
    "        # create 3d tensor [dapp_count,sequence_length,features]\n",
    "        data_tensor, labels_tensor= create_tensor_inputs(self.embedding_dir,dapp_addresses)\n",
    "        data_tensor = data_tensor.to(self.device)\n",
    "        results,result_before_bin_classifier = self.model(data_tensor.float())\n",
    "\n",
    "        # results shape = [dapp_count,1], result_before_bin_classifier = [dapp_count,sequence_length,features]\n",
    "        return results,result_before_bin_classifier "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
