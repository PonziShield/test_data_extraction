{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "import numpy as np\n",
    "# from DataBundle import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, embed_size, device):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    # Number of input features is embed_size. (108*7)\n",
    "    self.layer_1 = nn.Linear(embed_size, 64)\n",
    "    self.layer_2 = nn.Linear(64, 64)\n",
    "    self.layer_out = nn.Linear(64, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "    self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "    self.device = device\n",
    "    #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    #print(inputs)\n",
    "    #print(inputs.shape)\n",
    "    x = self.relu(self.layer_1(inputs))\n",
    "    x = self.batchnorm1(x)\n",
    "    x = self.relu(self.layer_2(x))\n",
    "    x = self.batchnorm2(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.layer_out(x)\n",
    "    #print(x)\n",
    "    #x = self.sigmoid(x)\n",
    "    #if math.isnan (x[0][0]):\n",
    "    #  print(src)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, d_model_tx, seq_len_tx, nhead_tx, dim_feedforward, nlayers_tx, device, dropout = 0.5):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.d_model_tx = d_model_tx\n",
    "\n",
    "    self.seq_len_tx = seq_len_tx\n",
    "\n",
    "    self.nhead_tx = nhead_tx\n",
    "\n",
    "    self.dim_feedforward = dim_feedforward\n",
    "    self.nlayers_tx = nlayers_tx\n",
    "\n",
    "    self.device = device\n",
    "    #self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "    self.position_embedding_tx = nn.Embedding(seq_len_tx, d_model_tx)\n",
    "\n",
    "    encoder_layer_tx = TransformerEncoderLayer(d_model_tx, nhead_tx, dim_feedforward, dropout, batch_first=True)\n",
    "\n",
    "    self.encoder_tx = TransformerEncoder(encoder_layer_tx, nlayers_tx)\n",
    "\n",
    "    self.binary_classifier = BinaryClassification((seq_len_tx*d_model_tx), device)\n",
    "\n",
    "\n",
    "  def forward(self, src_tx: Tensor) -> Tensor:\n",
    "    #print(\"Classifier forwrd\")\n",
    "    #print(src_rw)\n",
    "\n",
    "    N, seq_length, embed_size = src_tx.shape\n",
    "    positions_tx = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "    src_tx_ = src_tx + self.position_embedding_tx(positions_tx)\n",
    "\n",
    "\n",
    "    #print(f\"src after positional embeddings: {src.shape}\")\n",
    "    #print(src)\n",
    "    #print(\"before encoder\")\n",
    "    output_tx = self.encoder_tx(src_tx_)\n",
    "\n",
    "    #print(output_rw)\n",
    "    output_tx_f = torch.reshape(output_tx, (N, seq_length*embed_size))\n",
    "\n",
    "    #print(output_tx_f)\n",
    "    #print(f\"encoder output shape: {output.shape}\")\n",
    "    #print(output)\n",
    "    #print(\"after encoder\")\n",
    "    output = self.binary_classifier(torch.cat((output_tx_f), dim=1)) ##\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "  def __init__(self, d_model_tx, seq_len_tx, nhead_tx, dim_feedforward, nlayers_tx, device, dropout=0.5):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.d_model_tx = d_model_tx\n",
    "    self.seq_len_tx = seq_len_tx\n",
    "    self.nhead_tx = nhead_tx\n",
    "    self.  = dim_feedforward\n",
    "    self.nlayers_tx = nlayers_tx\n",
    "    self.device = device\n",
    "\n",
    "    # Embedding layer for positional encoding\n",
    "    self.position_embedding_tx = nn.Embedding(seq_len_tx, d_model_tx)\n",
    "\n",
    "    # Transformer Encoder Layer\n",
    "    encoder_layer_tx = TransformerEncoderLayer(d_model_tx, nhead_tx, dim_feedforward, dropout, batch_first=True)\n",
    "    \n",
    "    # Transformer Encoder\n",
    "    self.encoder_tx = TransformerEncoder(encoder_layer_tx, nlayers_tx)\n",
    "\n",
    "    # Binary Classification Layer\n",
    "    # This assumes you have a BinaryClassification class defined elsewhere\n",
    "    self.binary_classifier = BinaryClassification((seq_len_tx * d_model_tx), device)\n",
    "\n",
    "  def forward(self, src_tx: Tensor) -> Tensor:\n",
    "    # Calculate positional embeddings\n",
    "    N, seq_length, embed_size = src_tx.shape\n",
    "    positions_tx = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "    src_tx_ = src_tx + self.position_embedding_tx(positions_tx)\n",
    "\n",
    "    # Pass the source through the Transformer Encoder\n",
    "    output_tx = self.encoder_tx(src_tx_)\n",
    "\n",
    "    # Flatten the output for binary classification\n",
    "    output_tx_f = torch.reshape(output_tx, (N, seq_length * embed_size))\n",
    "\n",
    "    # Concatenate and pass through the binary classifier\n",
    "    output = self.binary_classifier(torch.cat((output_tx_f), dim=1))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "dim_feedforward=16\n",
    "#dim_feedforward=32\n",
    "nlayers_tx=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandu\\Desktop\\sem7\\fyp\\App\\.venv\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (position_embedding_tx): Embedding(108, 7)\n",
       "  (encoder_tx): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=7, out_features=7, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=7, out_features=16, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
       "        (norm1): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (binary_classifier): BinaryClassification(\n",
       "    (layer_1): Linear(in_features=756, out_features=64, bias=True)\n",
       "    (layer_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (layer_out): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (batchnorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batchnorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier(d_model_tx=7,  seq_len_tx=108,nhead_tx=7,  dim_feedforward=16, nlayers_tx=nlayers_tx, device=device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=1)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for X1_batch, y_batch in train_loader:\n",
    "        #print(\"w.requires_grad:\",X_batch.requires_grad)\n",
    "        X1_batch, y_batch = X1_batch.to(device),y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X1_batch.float())\n",
    "        #y_pred = (y_pred>0.5).float() \n",
    "        #print(f\"y_pred = {y_pred}\")\n",
    "        #print(f\"y_batch.unsqueeze(1) = {y_batch.unsqueeze(1)}\")\n",
    "        #print(y_pred)\n",
    "        #print(y_batch)\n",
    "\n",
    "        loss = criterion(y_pred.float(), y_batch.unsqueeze(1).float())\n",
    "        acc = binary_acc(y_pred.float(), y_batch.unsqueeze(1).float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    model.eval()\n",
    "    for X1_batch, y_batch in val_loader:\n",
    "        #print(\"w.requires_grad:\",X_batch.requires_grad)\n",
    "        X1_batch,  y_batch = X1_batch.to(device),  y_batch.to(device)\n",
    "\n",
    "        y_pred = model(X1_batch.float())\n",
    "        loss = criterion(y_pred.float(), y_batch.unsqueeze(1).float())\n",
    "        acc = binary_acc(y_pred.float(), y_batch.unsqueeze(1).float())\n",
    "        val_loss += loss.item()\n",
    "        val_accuracy += acc.item()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f} | Val_Loss: {val_loss/len(val_loader):.5f} | Val_Acc: {val_accuracy/len(val_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = './DeFi_Latest_v2.pth'\n",
    "#PATH = './DeFi_Latest_v3.pth' #transformer layers=4,4\n",
    "#PATH = './DeFi_Latest_v4.pth' #tranformer layers=8,8\n",
    "PATH = './DeFi_Latest_v4_1.pth' #tranformer layers=8,8\n",
    "#PATH = './DeFi_Latest_v5.pth' #transformer layers=12,12\n",
    "#PATH = './DeFi_Latest_v6.pth' #tranformer layers=8,8 epoch=50\n",
    "#PATH = './DeFi_Latest_v7.pth' #tranformer layers=8,8, ff=32, epoch=50\n",
    "#PATH = './DeFi_Latest_v4_2.pth' #tranformer layers=8,8, ff=32, epoch=10\n",
    "#torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "for X1_batch, y_batch in test_loader:\n",
    "        #print(\"w.requires_grad:\",X_batch.requires_grad)\n",
    "        X1_batch, X2_batch, y_batch = X1_batch.to(device), X2_batch.to(device), y_batch.to(device)\n",
    "        y_batch_pred = torch.round(sigmoid(loaded_model(X1_batch.float())))\n",
    "        y_pred.extend(y_batch_pred.cpu().detach().numpy())\n",
    "        y_true.extend(y_batch.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Dataset\n",
    "count_true = 0\n",
    "for i in range(len(y_pred)):\n",
    "  if y_true[i]==y_pred[i]:\n",
    "    count_true+=1\n",
    "acc = count_true/len(y_pred)\n",
    "print(len(y_test))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1), index = ['0','1'],\n",
    "                     columns = ['0','1'])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('output.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
